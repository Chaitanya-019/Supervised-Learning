In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm.
A hyperparameter is a parameter whose value is used to control the learning process.
By contrast, the values of other parameters (typically node weights) are learned.

The same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns.
These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem.
Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data.
The objective function takes a tuple of hyperparameters and returns the associated loss.
Cross-validation is often used to estimate this generalization performance.
